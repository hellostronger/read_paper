## 论文地址
https://arxiv.org/abs/2102.05918

## 基本信息
- **标题**: Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision
- **作者**: Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Le, Yun-Hsuan Sung, Zhen Li, Tom Duerig
- **机构**: Google Research
- **发布时间**: 2021年2月
- **代码**: -

## 核心问题：ALIGN

传统视觉-语言模型依赖人工标注的数据集，规模有限且成本高昂。本文探索如何利用互联网级别的大规模噪声图文数据来训练视觉和视觉-语言表示模型。

## 核心方法：ALIGN
### 1. 大规模噪声数据收集
收集超过18亿个图像-文本配对数据（从网络上获取的alt-text描述）

### 2. 双编码器架构
使用独立的图像编码器和文本编码器，将图像和文本映射到统一的向量空间

### 3. 对比学习目标
使用对比损失（InfoNCE）训练，使匹配的图像-文本对在特征空间中靠近

**InfoNCE 损失公式：**

对于一个batch中的 $N$ 个图像-文本对，InfoNCE loss定义为：

$$\mathcal{L}_{I2T} = -\frac{1}{N} \sum_{i=1}^{N} \log \frac{\exp(sim(I_i, T_i) / \tau)}{\sum_{j=1}^{N} \exp(sim(I_i, T_j) / \tau)}$$

$$\mathcal{L}_{T2I} = -\frac{1}{N} \sum_{i=1}^{N} \log \frac{\exp(sim(T_i, I_i) / \tau)}{\sum_{j=1}^{N} \exp(sim(T_i, I_j) / \tau)}$$

**总损失：**

$$\mathcal{L} = \frac{1}{2} (\mathcal{L}_{I2T} + \mathcal{L}_{T2I})$$

其中：
- $I_i, T_i$ 分别是第 $i$ 个图像和文本的归一化嵌入向量
- $sim(u, v) = u^T v = \cos(u, v)$ 表示余弦相似度
- $\tau$ 是温度系数（temperature），用于控制相似度分布的平滑程度
- 分子表示匹配对 $(I_i, T_i)$ 的相似度得分
- 分母是所有负样本对的相似度得分之和（Softmax归一化）

#### [可选：详细组件说明]
| 组件 | 架构选择 | 输出维度 | 说明 |
|-----|---------|---------|------|
| **图像编码器** | EfficientNet | - | 将图像编码为特征向量 |
| **文本编码器** | 简单文本编码器 | - | 将文本描述编码为特征向量 |
| **投影层** | Linear | - | 将特征投影到统一嵌入空间 |

#### [可选：相关模型发布时间对比]
| 模型 | 论文 | 时间 |
|-----|------|------|
| CLIP | Learning Transferable Visual Models From Natural Language Supervision | 2021.3 |
| ALIGN | Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision | 2021.2 |

#### [可选：训练配置]
| 配置项 | 说明 |
|-------|------|
| 训练数据 | 18亿图像-文本配对 |
| 损失函数 | InfoNCE / 对比损失 |
| 优化器 | - |

#### [可选：推理流程]
零样本分类流程：
1. 将待分类的类别名称转换成文本描述
2. 使用文本编码器生成类别文本嵌入
3. 使用图像编码器生成图像嵌入
4. 计算图像与所有文本描述的余弦相似度
5. 选择相似度最高的类别

## 主要贡献

1. 证明了**规模化**是关键：大规模噪声数据可以训练出与人工标注数据质量相当的模型
2. 在多个视觉-语言任务上达到SOTA，包括图像-文本检索、零样本分类等
3. 展示了简单双编码器架构 + 大规模预训练的有效性
4. 为后续多模态模型（如CLIP）提供了重要参考

## 实验结果
### 零样本图像分类
在ImageNet等基准上，ALIGN达到与监督模型相当甚至更好的性能

### 图像-文本检索
在Flickr30K、COCO等检索任务上显著超越之前方法

### 消融实验
证明了数据规模、模型容量对性能的重要影响

## 核心洞察

1. **规模化优先**：大数据量的噪声可以被稀释，简单方法+大数据 > 复杂方法+小数据
2. 双编码器的计算效率使其可以扩展到超大规模训练
3. 互联网本身就是最大的标注数据集

## 局限性与未来方向

1. 训练数据中的噪声和偏差可能传播到下游任务
2. 对细粒度理解任务仍有提升空间
3. 后续工作探索了更精细的数据过滤策略

## 核心价值

ALIGN与CLIP几乎同期提出，共同开创了**对比学习 + 大规模图文预训练**的新范式，为DALL-E、Stable Diffusion等多模态生成模型奠定了基础。

## 阅读笔记

---

## 参考知识点介绍
[^1]: **术语** - 定义

## 常见损失函数对比
| 损失函数 | 适用场景 | 公式特点 |
|---------|---------|---------|
| | | |
